{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_extraction import DataExtractor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from io import StringIO\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = DataExtractor.extract_from_s3()\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_cleaning \n",
    "\n",
    "product_df = DataCleaning.convert_product_weights(product_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaning:\n",
    "    @staticmethod\n",
    "    def convert_product_weights(products_df):\n",
    "        \"\"\"Converts product weights to kg and cleans the weight column.\"\"\"\n",
    "\n",
    "        def convert_to_kg(value):\n",
    "            \"\"\"Helper function to convert weight to kg.\"\"\"\n",
    "            # If the value is already a float (indicating no units), return it as is\n",
    "            if isinstance(value, float):\n",
    "                return value\n",
    "\n",
    "            try:\n",
    "                # Detect calculation (e.g., \"2x250ml\") and evaluate it\n",
    "                if 'x' in value:\n",
    "                    parts = value.split('x')\n",
    "                    if len(parts) == 2:\n",
    "                        num, unit_value = parts\n",
    "                        # Remove non-numeric characters from unit_value for multiplication\n",
    "                        unit_value = re.sub(r'[^0-9.]', '', unit_value)\n",
    "                        # Perform the multiplication and then continue with the conversion\n",
    "                        value = str(float(num) * float(unit_value))\n",
    "\n",
    "\n",
    "                # Check for 'kg' in weight and convert to float\n",
    "                if 'kg' in value:\n",
    "                    return float(value.replace('kg', ''))\n",
    "                elif '77g .' == value:  # Specific case with an extra period\n",
    "                    return 77.0 / 1000  # Convert 77g to kg\n",
    "                # Check for 'g' in weight and convert to kg\n",
    "                elif 'g' in value:\n",
    "                    return float(value.replace('g', '')) / 1000\n",
    "                # Check for 'ml' and assume 1:1 ratio with 'g', then convert to kg\n",
    "                elif 'ml' in value:\n",
    "                    return float(value.replace('ml', '')) / 1000\n",
    "                elif value == '16oz':  # Specific case with ounces\n",
    "                    return 16 * 0.0283495  # Convert 16oz to kg\n",
    "                else:\n",
    "                    # If no known unit, assume it's already in kg\n",
    "                    return float(value)\n",
    "            except ValueError as e:\n",
    "                # If there's a ValueError, print it and return None to handle it later\n",
    "                print(f\"Error converting '{value}': {e}\")\n",
    "                return None\n",
    "\n",
    "        # Apply the conversion to each entry in the weight column\n",
    "        products_df['weight'] = products_df['weight'].apply(convert_to_kg)\n",
    "        \n",
    "        # If there was an error during conversion, the result will be None, so we can drop these rows or handle them\n",
    "        products_df = products_df.dropna(subset=['weight'])\n",
    "        \n",
    "        return products_df\n",
    "\n",
    "# Instantiate the DataCleaning class\n",
    "data_cleaner = DataCleaning()\n",
    "\n",
    "# Apply the method to the DataFrame\n",
    "df_cleaned_weights = data_cleaner.convert_product_weights(product_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaning:\n",
    "    @staticmethod\n",
    "    def convert_to_kg(value):\n",
    "        \"\"\"Helper function to convert weight to kg.\"\"\"\n",
    "        # If the value is already a float (indicating no units), return it as is\n",
    "        if isinstance(value, float):\n",
    "            return value\n",
    "        \n",
    "        try:\n",
    "            # Detect calculation (e.g., \"2x250ml\") and evaluate it\n",
    "            if 'x' in value:\n",
    "                parts = value.split('x')\n",
    "                if len(parts) == 2:\n",
    "                    num, unit_value = parts\n",
    "                    # Remove non-numeric characters from unit_value for multiplication\n",
    "                    unit_value = re.sub(r'[^0-9.]', '', unit_value)\n",
    "                    # Perform the multiplication and then continue with the conversion\n",
    "                    value = str(float(num) * float(unit_value))\n",
    "\n",
    "            # Check for 'kg' in weight and convert to float\n",
    "            if 'kg' in value:\n",
    "                return float(value.replace('kg', ''))\n",
    "            # Check for 'g' in weight and convert to kg\n",
    "            elif 'g' in value:\n",
    "                return float(value.replace('g', '')) / 1000\n",
    "            # Check for 'ml' and assume 1:1 ratio with 'g', then convert to kg\n",
    "            elif 'ml' in value:\n",
    "                return float(value.replace('ml', '')) / 1000\n",
    "            # Check for specific cases that caused errors before\n",
    "            elif value == '77g .':  # Specific case with an extra period\n",
    "                return 77.0 / 1000  # Convert 77g to kg\n",
    "            elif value == '16oz':  # Specific case with ounces\n",
    "                return 16 * 0.0283495  # Convert 16oz to kg\n",
    "            else:\n",
    "                # If no known unit, assume it's already in kg\n",
    "                return float(value)\n",
    "        except ValueError as e:\n",
    "            # If there's a ValueError, print it and return None to handle it later\n",
    "            print(f\"Error converting '{value}': {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "    @staticmethod       \n",
    "    def convert_product_weights(self, products_df):\n",
    "        \"\"\"Converts product weights to kg and cleans the weight column.\"\"\"\n",
    "        # Apply the conversion to each entry in the weight column\n",
    "        products_df['weight'] = products_df['weight'].DataCleaning.convert_to_kg()\n",
    "        \n",
    "        # If there was an error during conversion, the result will be None, so we can drop these rows or handle them\n",
    "        #products_df = products_df.dropna(subset=['weight'])\n",
    "        \n",
    "        return products_df\n",
    "\n",
    "# Instantiate the DataCleaning class\n",
    "data_cleaner = DataCleaning()\n",
    "\n",
    "# Apply the method to the DataFrame\n",
    "df_cleaned_weights = data_cleaner.convert_product_weights(product_df['weight'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "print(product_df['weight'].sample(50))\n",
    "\n",
    "conversion_factors = {\"g\" : 1, \"mg\" :0.001, \"ml\": 1, 'kg': 1000}\n",
    "\n",
    "def convert_weight(weight):\n",
    "    if isinstance(weight, str):\n",
    "        match = re.match(r'(\\d+\\.?\\d*)\\s*([a-zA-Z]+)', weight)\n",
    "        if match:\n",
    "            value, unit = match.groups()\n",
    "            value = float(value)\n",
    "            unit = unit.lower()\n",
    "            #Convert the values to grams        \n",
    "            value *= conversion_factors.get(unit, 1)\n",
    "            #Divide by 1000 to convert to kilograms\n",
    "            return value/1000\n",
    "        else:\n",
    "            print(f'No unit found for weight: {weight}')\n",
    "            return weight\n",
    "        \n",
    "product_df['weight_kg'] = product_df['weight'].apply(convert_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "product_df = DataExtractor.extract_from_s3()\n",
    "\n",
    "#print(product_df['weight'].sample(50))\n",
    "\n",
    "conversion_factors = {\"g\" : 1, \"mg\" :0.001, \"ml\": 1, 'kg': 1000}\n",
    "\n",
    "def convert_weight(weight):\n",
    "    if isinstance(weight, str):\n",
    "        match = re.match(r'(\\d+\\.?\\d*)\\s*([a-zA-Z]+)', weight)\n",
    "        if match:\n",
    "            value, unit = match.groups()\n",
    "            value = float(value)\n",
    "            unit = unit.lower()\n",
    "            #Convert the values to grams        \n",
    "            value *= conversion_factors.get(unit, 1)\n",
    "            #Divide by 1000 to convert to kilograms\n",
    "            return value/1000\n",
    "        else:\n",
    "            print(f'No unit found for weight: {weight}')\n",
    "            return weight\n",
    "    elif isinstance(weight, (int, float)):\n",
    "        return weight/1000\n",
    "    \n",
    "product_df['weight_kg'] = product_df['weight'].apply(convert_weight)\n",
    "print(product_df['weight_kg'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_weight(weight):\n",
    "    # Match patterns like '12 x 100g' or '6 x 400ml' \n",
    "    if isinstance(weight, str):\n",
    "        match = re.match(r'(\\d+)\\s*x\\s*(\\d+\\.?\\d*)([a-zA-Z]+)', weight)\n",
    "        if match:\n",
    "            quantity, value, unit = match.groups()\n",
    "            quantity = float(quantity)\n",
    "            value = float(value)\n",
    "            unit = unit.lower()\n",
    "            #Convert the values to grams\n",
    "            if unit in conversion_factors:\n",
    "                value *= conversion_factors[unit]\n",
    "            #Divid by 1000 since we want everything in kg\n",
    "            return (quantity * value) / 1000\n",
    "        else:\n",
    "            print(f'No unit found for weight: {weight}')\n",
    "            return None\n",
    "    elif isinstance(weight, (int, float)):\n",
    "            return weight/1000\n",
    "    \n",
    "product_df['weight_kg'] = product_df['weight'].apply(convert_weight)\n",
    "print(product_df['weight_kg'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data = DataExtractor.retrieve_stores_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(product_df['weight'].unique())\n",
    "print(product_df['weight'][1852])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data.replace('NULL', np.nan, inplace=True)\n",
    "store_data = store_data.dropna(subset=['store_type'])\n",
    "valid_store_types = ['Local', 'Super Store', 'Mall Kiosk', 'Outlet']\n",
    "store_data = store_data[store_data['store_type'].isin(valid_store_types)]\n",
    "store_data['opening_date'] = pd.to_datetime(store_data['opening_date'], errors = 'coerce', format ='%Y-%m-%d')\n",
    "store_data = store_data.drop_duplicates(subset=['address'])\n",
    "store_data['staff_numbers'] = pd.to_numeric(store_data['staff_numbers'], errors = 'coerce')\n",
    "#store_data['staff_numbers'] = store_data['staff_numbers'].astype(int)\n",
    "valid_country_codes = ['GB', 'DE', 'US']\n",
    "store_data = store_data[store_data['country_code'].isin(valid_country_codes)]\n",
    "store_data['country_code'] = store_data['country_code'].astype('category')\n",
    "\n",
    "continent_corrections = { 'eeEurope': 'Europe', 'eeAmerica': 'America'}\n",
    "store_data['continent'] = store_data['continent'].replace(continent_corrections)\n",
    "rows_to_drop = store_data[store_data['continent'].isin(['NULL', 'QMAVR5H3LD', 'LU3E036ZD9', \n",
    "                                           '5586JCLARW', 'GFJQ2AAEQ8', 'SLQBD982C0', \n",
    "                                           'XQ953VS0FG', '1WZB1TE1HL'])].index\n",
    "store_data = store_data.drop(rows_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(product_df['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(store_data['lat'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(store_data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated = stores.duplicated(subset=['address'])\n",
    "\n",
    "stores[duplicated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('api_creds.yaml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    api_key = config['api']['x-api-key']\n",
    "except FileNotFoundError:\n",
    "    print(\"The YAML configuration file was not found.\")\n",
    "except KeyError as e:\n",
    "    print(f\"A key error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'J78': Contains a letter.\n",
    "'30e': Contains a letter, looks like it could be scientific notation but in the context of staff numbers, this is likely not valid.\n",
    "'80R': Contains a letter.\n",
    "'A97': Contains a letter.\n",
    "'3n9': Contains a letter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(store_data['staff_numbers'].unique())\n",
    "\n",
    "staff_corrections = {'J78' : '78', '30e':'30', '80R':'80', 'A97' :'97', \"3n9\" : '39'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_2['card_provider'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_2['expiry_date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_2['card_number'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_cleaning import DataCleaning\n",
    "from data_extraction import DataExtractor\n",
    "from database_utils import DatabaseConnector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatabaseConnector.list_db_tables()\n",
    "orders_table = DataExtractor.read_rds_table('orders_table')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_orders_data(orders_table):\n",
    "    clean_orders_table = orders_table.drop(['level_0', 'first_name', 'last_name', 'index', \"1\"], axis = 1)\n",
    "    return clean_orders_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_table = clean_orders_data(orders_table)\n",
    "cleaned_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataExtractor.extract_from_s3('https://data-handling-public.s3.eu-west-1.amazonaws.com/date_details.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "\n",
    "response = requests.get(\"https://data-handling-public.s3.eu-west-1.amazonaws.com/date_details.json\")\n",
    "\n",
    "if response.status_code != 200:\n",
    "    raise Exception(f'Failed to fetch data: {response.status_code}')\n",
    "content = response.content.decode('utf-8')\n",
    "events_data = pd.read_json(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_data.to_csv('events_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Combine 'year', 'month', and 'day' into a single date string\n",
    "events_data['combined_date'] = events_data['year'].astype(str) + '-' + \\\n",
    "                                     events_data['month'].astype(str) + '-' + \\\n",
    "                                     events_data['day'].astype(str)\n",
    "\n",
    "# 3. Convert the combined date string to datetime and drop rows where conversion fails\n",
    "events_data['date'] = pd.to_datetime(events_data['combined_date'], errors='coerce')\n",
    "events_data = events_data.dropna(subset=['date'])\n",
    "\n",
    "# 4. Drop the now redundant 'year', 'month', 'day', and 'combined_date' columns\n",
    "events_data = events_data.drop(['year', 'month', 'day', 'combined_date'], axis=1)\n",
    "\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 120123 entries, 0 to 120160\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   timestamp    120123 non-null  object        \n",
      " 1   time_period  120123 non-null  object        \n",
      " 2   date_uuid    120123 non-null  object        \n",
      " 3   date         120123 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "events_data['timestamp'] = pd.to_datetime(events_data['timestamp'], format='%H:%M:%S').dt.time\n",
    "events_data\n",
    "\n",
    "events_data['time_period'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Evening', 'Morning', 'Midday', 'Late_Hours'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_data['time_period'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
